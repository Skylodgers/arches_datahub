{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90eb3bf2-36ac-4f5a-bcec-1d45493d048f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from django_for_jupyter import init_django\n",
    "init_django(\"arches\")\n",
    "\n",
    "import json\n",
    "import pprint \n",
    "import uuid\n",
    "\n",
    "import pandas as pd\n",
    "from lxml import etree\n",
    "from collections import OrderedDict\n",
    "\n",
    "import base64\n",
    "from IPython.display import Image, display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from arches.app.utils.data_management.resource_graphs.exporter import get_graphs_for_export as get_graph\n",
    "from arches.app.utils.data_management.resource_graphs.exporter import create_mapping_configuration_file as get_mapping\n",
    "from arches.app.utils.data_management.resource_graphs.exporter import export as export_gephi\n",
    "\n",
    "\n",
    "from django.core.serializers.json import DjangoJSONEncoder\n",
    "\n",
    "dataset_uuid = \"af04eac2-a131-11ed-a102-9cf387da2c40\"\n",
    "\n",
    "#dataset_uuid = \"b36ccfad-0686-4213-9511-1481b86a9e21\" # Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1285e879-aed0-4aeb-b4f5-11127820b318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_graph_as_json(_uuid):\n",
    "    gr = get_graph([_uuid])\n",
    "    return json.dumps(gr['graph'], indent=2, cls=DjangoJSONEncoder)\n",
    "\n",
    "_graph = get_graph_as_json(\"b36ccfad-0686-4213-9511-1481b86a9e21\")\n",
    "#print(_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36eaa34d-4085-45ce-9e49-4896fbd611ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_graph_as_json(_uuid):\n",
    "    _graph = get_graph([_uuid])\n",
    "    return _graph\n",
    "\n",
    "def make_cards_df(graph):\n",
    "    c_df = pd.DataFrame(graph['graph'][0]['cards']).sort_values(by=['sortorder'])\n",
    "    for idx, row in c_df.iterrows():\n",
    "        c_df.loc[idx, 'cardid'] = str(row['cardid'])\n",
    "    c_df.to_csv('exporter/out/01_cards.csv', index=False)\n",
    "    return c_df\n",
    "\n",
    "def make_edges_df(graph):\n",
    "    df = pd.DataFrame(graph['graph'][0]['edges'])\n",
    "    df.to_csv('exporter/out/02_edges.csv', index=False)\n",
    "    return df \n",
    "\n",
    "def make_nodes_df(graph):\n",
    "    df = pd.DataFrame(graph['graph'][0]['nodes'])\n",
    "    df.to_csv('exporter/out/03_nodes.csv', index=False)\n",
    "    return df\n",
    "\n",
    "def make_xx_df(graph):\n",
    "    df = pd.DataFrame(graph['graph'][0]['cards_x_nodes_x_widgets'])        \n",
    "    for idx, row in df.iterrows():\n",
    "        df.loc[idx, 'sortorder'] = str(row['sortorder']).replace('.0', '')\n",
    "    df.to_csv('exporter/out/04_xx.csv', index=False)\n",
    "    return df\n",
    "                    \n",
    "# ---------------------------\n",
    "def add_edges_to_nodes(edges, nodes):\n",
    "    \n",
    "    for n_idx, n_row in nodes.iterrows():\n",
    "        n_node_id = str(n_row['nodeid'])        \n",
    "        n_name = str(n_row['name'])        \n",
    "        for e_idx, e_row in edges.iterrows():\n",
    "            e_domainnode_id = str(e_row['domainnode_id'])\n",
    "            e_rangenode_id = str(e_row['rangenode_id'])\n",
    "            if e_rangenode_id == n_node_id:  \n",
    "                nodes.loc[n_idx, 'domainnode_id'] = e_domainnode_id\n",
    "                nodes.loc[n_idx, 'rangenode_id'] = e_rangenode_id\n",
    "                nodes.loc[n_idx, 'edgeid'] = str(e_row['edgeid'])\n",
    "                #nodes.loc[e_idx, 'ontologyproperty'] = str(e_row['ontologyproperty'])                    \n",
    "                \n",
    "                # add parents                \n",
    "                parent = nodes.loc[nodes['nodeid'] == e_domainnode_id]['name'].values.tolist()[0]\n",
    "                nodes.loc[n_idx, 'parent'] = parent\n",
    "                parent = ''\n",
    "    nodes.to_csv('exporter/out/05_nodes_edges.csv', index=False)\n",
    "    return nodes\n",
    "\n",
    "def add_cards_to_nodes_edges(cards, node_edges):\n",
    "    \n",
    "    for n_idx, n_row in node_edges.iterrows():\n",
    "        n_nodegroup_id = str(n_row['nodegroup_id'])\n",
    "        n_name = str(n_row['name'])\n",
    "        for c_idx, c_row in cards_df.iterrows():\n",
    "            c_nodegroup_id = str(c_row['nodegroup_id'])\n",
    "            c_name = str(c_row['name']['en'])\n",
    "            if n_nodegroup_id == c_nodegroup_id:\n",
    "                    node_edges.loc[n_idx, 'card_id'] = str(c_row['cardid'])\n",
    "                    \n",
    "                    \n",
    "                    #\n",
    "                    #\n",
    "                    #\n",
    "                    #node_edges.loc[n_idx, 'node_card_sortorder'] = str(c_row['sortorder']).replace('.0', '')\n",
    "                    node_edges.loc[n_idx, 'node_card_sortorder'] = int(c_row['sortorder'])\n",
    "                    #\n",
    "                    #\n",
    "                    #\n",
    "                    #\n",
    "                    \n",
    "                    # add the rest that's needed\n",
    "                    node_edges.loc[n_idx, 'instructions'] = str(c_row['instructions'])\n",
    "                    node_edges.loc[n_idx, 'helptitle'] = str(c_row['helptitle'])\n",
    "                    node_edges.loc[n_idx, 'helptext'] = str(c_row['helptext'])\n",
    "                    node_edges.loc[n_idx, 'visible'] = str(c_row['visible'])\n",
    "\n",
    "                    \n",
    "        if pd.isnull(node_edges.loc[n_idx, 'parent']):\n",
    "            node_edges.loc[n_idx, 'parent'] = 'root'\n",
    "            node_edges.loc[n_idx, 'node_card_sortorder'] = 0\n",
    "            node_edges.loc[n_idx, 'domainnode_id'] = 'RDF'\n",
    "            #node_edges.loc[n_idx, 'domainnode_id'] = str(n_row['nodeid'])\n",
    "            node_edges.loc[n_idx, 'rangenode_id'] = str(n_row['nodeid'])\n",
    "\n",
    "    node_edges['node_card_sortorder'] = node_edges['node_card_sortorder'].astype('int')        \n",
    "    node_edges.to_csv('exporter/out/06_nodes_edges_cards.csv', index=False)\n",
    "    return node_edges\n",
    "\n",
    "def add_xx_to_nodes_edges_cards(xx, edges_node_cards):\n",
    "    \n",
    "    for e_idx, e_row in edges_node_cards.iterrows():\n",
    "        e_node_id = str(e_row['nodeid'])\n",
    "        for x_idx, x_row in xx.iterrows():\n",
    "            x_node_id = str(x_row['node_id'])\n",
    "            if e_node_id == x_node_id:\n",
    "                edges_node_cards.loc[e_idx, 'card_sortorder'] = str(x_row['sortorder'])\n",
    "            \n",
    "    edges_node_cards.to_csv('exporter/out/07_nodes_edges_cards_xx.csv', index=False)\n",
    "    return edges_node_cards\n",
    "\n",
    "\n",
    "# ---------------------------\n",
    "\n",
    "\n",
    "ONTOLOGY_NAMESPACES = {\n",
    "    #'http://my_namespace_here/': 'some_ns',\n",
    "    \"http://www.w3.org/1999/02/22-rdf-syntax-ns#\": \"RDF\",\n",
    "    \"http://www.w3.org/2001/XMLSchema#\": \"xsd\",\n",
    "    \"http://www.w3.org/2000/01/rdf-schema#\": \"rdfs\",\n",
    "    \"http://www.cidoc-crm.org/cidoc-crm/\": \"crm\",\n",
    "    \"http://www.ics.forth.gr/isl/CRMarchaeo/\": \"CRMarchaeo\",\n",
    "    \"http://www.ics.forth.gr/isl/CRMdig/\": \"CRMdig\",\n",
    "    \"http://www.ics.forth.gr/isl/CRMgeo/\": \"CRMgeo\",\n",
    "    \"http://www.ics.forth.gr/isl/CRMinf/\": \"CRMinf\",\n",
    "    \"http://www.ics.forth.gr/isl/CRMsci/\": \"CRMsci\",\n",
    "    \"http://parthenos.d4science.org/CRMext/CRMpe.rdfs/\": \"CRMpe\",\n",
    "    \"https://takin.solutions/ontologies/CRMsurv/\": \"CRMsurv\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def add_namespace_suffix(graph):\n",
    "\n",
    "    def make_namespace_suffix(url):\n",
    "        if '#' in url:\n",
    "            url_split = url.split('#')\n",
    "            class_prop = url_split[-1:][0]\n",
    "            namespace_prefix = url_split[0] + '#'\n",
    "        else:\n",
    "            url_split = url.split('/')\n",
    "            class_prop = url_split[-1:][0]\n",
    "            namespace_prefix = '/'.join(url_split[:-1]) + '/'\n",
    "        namespace = ONTOLOGY_NAMESPACES.get(namespace_prefix)    \n",
    "        return '%s:%s' % (namespace, class_prop)\n",
    "\n",
    "    for idx, row in graph.iterrows():\n",
    "        graph.loc[idx, 'sip_property'] = make_namespace_suffix(row['parentproperty'])\n",
    "        if row['parent'] == 'root':\n",
    "            graph.loc[idx, 'sip_property'] = 'RDF'\n",
    "            graph.loc[idx, 'sip_class'] = make_namespace_suffix(row['ontologyclass'])\n",
    "        else:    \n",
    "            graph.loc[idx, 'sip_class'] = make_namespace_suffix(row['ontologyclass'])\n",
    "                \n",
    "    graph.to_csv('exporter/out/08_graph_ns.csv', index=False)\n",
    "    return graph\n",
    "\n",
    "\n",
    "def build_paths(graph):\n",
    "\n",
    "    graph = graph.sort_values(by=['node_card_sortorder', 'card_sortorder', 'parent'])\n",
    "    \n",
    "    path_list = []\n",
    "    path_dict = []\n",
    "    parents = set()\n",
    "    children = {}\n",
    "\n",
    "    for idx, row in graph.iterrows():\n",
    "        children[row['rangenode_id']] = row['domainnode_id']\n",
    "            \n",
    "    def ancestors(p):\n",
    "        return (ancestors(children[p]) if p in children else []) + [p]\n",
    "\n",
    "    for k in (set(children.keys())):\n",
    "        path_list.append(ancestors(k))\n",
    "        \n",
    "    for idx, row in graph.iterrows():\n",
    "        node_id = str(row['nodeid'])\n",
    "        \n",
    "        for path in path_list:\n",
    "            if node_id == path[-1]:                \n",
    "                graph.loc[idx, 'path'] = str(path)\n",
    "                graph.loc[idx, 'path_length'] = str(len(path))\n",
    "        if row['domainnode_id'] == 'RDF':\n",
    "            graph.loc[idx, 'domainnode_id'] = None\n",
    "            graph.loc[idx, 'rangenode_id'] = str(row['nodeid'])    \n",
    "\n",
    "    \n",
    "    graph.to_csv('exporter/out/09_graph_path.csv', index=False)            \n",
    "    return graph            \n",
    "                \n",
    "\n",
    "def make_ns_paths(graph):\n",
    "    \n",
    "    path_list = []\n",
    "    path_dict = {}\n",
    "    doc_paths = []\n",
    "        \n",
    "    path_df = graph[['nodeid', 'path']]\n",
    "    path_list = []\n",
    "    path_dict = {}\n",
    "    doc_path = []\n",
    "        \n",
    "    for p_idx, p_row in path_df.iterrows():\n",
    "        paths = p_row['path'].strip('][').replace(\"'\", \"\").split(', ')           \n",
    "        for item in paths:\n",
    "            if item != 'RDF':\n",
    "                path_row = graph.loc[graph['nodeid'] == item]\n",
    "                _property = path_row['sip_property'].values.tolist()[0]\n",
    "                _class = path_row['sip_class'].values.tolist()[0]\n",
    "                path_list.append(str(_property))\n",
    "                path_list.append(str(_class))\n",
    "                _name = path_row['name'].values.tolist()[0]\n",
    "        \n",
    "        path_dict = {\"nodeid\": p_row['nodeid'], \"name\": _name, \"path\": path_list}\n",
    "        path_list = []\n",
    "        doc_paths.append(path_dict)\n",
    "        path_dict = {}\n",
    "\n",
    "    for idx, row in graph.iterrows():\n",
    "        for item in doc_paths:            \n",
    "            if row['nodeid'] == item['nodeid']:\n",
    "#                print(json.dumps(item, indent=2))\n",
    "#                print('_-')\n",
    "                graph.loc[idx, 'ns_path'] = [item]\n",
    "\n",
    "    doc_paths = []\n",
    "    graph = graph.sort_values(by=['node_card_sortorder', 'path_length', 'card_sortorder', 'parent'])\n",
    "    graph.to_csv('exporter/out/10_graph_ns_path.csv', index=False)    \n",
    "    return graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29c97bd5-6a11-4155-aadd-0c294cef31d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m graph \u001b[38;5;241m=\u001b[39m get_graph_as_json(dataset_uuid)\n\u001b[0;32m----> 3\u001b[0m edges_df \u001b[38;5;241m=\u001b[39m \u001b[43mmake_edges_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m nodes_df \u001b[38;5;241m=\u001b[39m make_nodes_df(graph)\n\u001b[1;32m      5\u001b[0m cards_df \u001b[38;5;241m=\u001b[39m make_cards_df(graph)\n",
      "Cell \u001b[0;32mIn[3], line 13\u001b[0m, in \u001b[0;36mmake_edges_df\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_edges_df\u001b[39m(graph):\n\u001b[0;32m---> 13\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[43mgraph\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgraph\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124medges\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     14\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexporter/out/02_edges.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "graph = get_graph_as_json(dataset_uuid)\n",
    "\n",
    "edges_df = make_edges_df(graph)\n",
    "nodes_df = make_nodes_df(graph)\n",
    "cards_df = make_cards_df(graph)\n",
    "xx_df = make_xx_df(graph)\n",
    "\n",
    "node_edges_df = add_edges_to_nodes(edges_df, nodes_df)\n",
    "node_edges_cards_df = add_cards_to_nodes_edges(cards_df, node_edges_df)\n",
    "node_edges_cards_xx_df = add_xx_to_nodes_edges_cards(xx_df, node_edges_cards_df)\n",
    "\n",
    "graph_ns = add_namespace_suffix(node_edges_cards_xx_df)\n",
    "graph_path = build_paths(graph_ns)\n",
    "\n",
    "graph = make_ns_paths(graph_path)\n",
    "\n",
    "print('done')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb20cb-0839-4c30-a92f-1e90bee3319a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_doc_paths(ns_graph):\n",
    "    \n",
    "    doc_dict = {}\n",
    "    doc_list = []\n",
    "\n",
    "    for idx, row in ns_graph.iterrows():        \n",
    "        node_id = row['nodeid']\n",
    "        \n",
    "        # For some weird reason the first row stores ns_path as dict, not list\n",
    "        if isinstance(row['ns_path'], dict):\n",
    "            ns_path = row['ns_path']\n",
    "        elif isinstance(row['ns_path'], list):   \n",
    "            ns_path = row['ns_path'][0]\n",
    "\n",
    "        name = row['name']\n",
    "        parent = row['parent']\n",
    "        node_card_sortorder = row['node_card_sortorder']\n",
    "        description = row['description']\n",
    "        datatype = row['datatype']\n",
    "        isrequired = row['isrequired']\n",
    "        isvisible = \"\" if pd.isna(ns_graph.loc[idx, 'visible']) else row['visible']\n",
    "        instructions = \"\" if pd.isna(ns_graph.loc[idx, 'instructions']) else row['instructions']\n",
    "        helptitle = \"\" if pd.isna(ns_graph.loc[idx, 'helptitle']) else row['helptitle']\n",
    "        helptext = \"\" if pd.isna(ns_graph.loc[idx, 'helptext']) else row['helptext']\n",
    "        \n",
    "        doc_dict = {\"nodeid\": node_id, \"path\": ns_path['path'], \"name\": name, \"parent\": parent, \"node_card_sortorder\": node_card_sortorder,\n",
    "                    \"datatype\": datatype, \"isrequired\": isrequired, \"isvisible\": isvisible, \"description\": description,\n",
    "                    \"instructions\": instructions, \"helptitle\": helptitle, \"helptext\": helptext, \n",
    "                    \"relation\": {name: parent}, 'datatype': datatype}\n",
    "                    \n",
    "        doc_list.append(doc_dict)\n",
    "        ns_graph.loc[idx, 'doc_path'] = [doc_dict]\n",
    "        doc_dict = {}\n",
    "    \n",
    "    ns_graph.to_csv('exporter/out/20_graph_nsa_path.csv', index=False)        \n",
    "    return doc_list\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de406938-5f37-444f-974a-a100171687bf",
   "metadata": {},
   "source": [
    "## Make rec_defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2017faa9-df4b-473a-8130-af62b3082d65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def make_rec_defs(_graph):\n",
    "    \n",
    "  \n",
    "    nodes = make_doc_paths(_graph)\n",
    "\n",
    "    item_list = []\n",
    "    children = {} #OrderedDict()\n",
    "    \n",
    "    for item in nodes:\n",
    "        #print(item['path'])\n",
    "        children[item['name']] = item['parent']\n",
    "            \n",
    "    for node in nodes:\n",
    "        def tree(p):\n",
    "            return (tree(children[p]) if p in children else []) + [p]\n",
    "        #print(list(node['relation'])[0])\n",
    "        _tree = tree(list(node['relation'])[0])        \n",
    "        _tag = node['path'][-1]\n",
    "        \n",
    "        if len(_tree) == 2:\n",
    "            root = etree.Element(\"root\", tag=\"RDF\") \n",
    "            node_map = etree.SubElement(root, \"node-mapping\", inputPath=\"/input\")\n",
    "            elem2 = etree.SubElement(root, \"elem\", tag = _tag)\n",
    "            attr = etree.SubElement(elem2, \"attr\", uriCheck=\"True\", tag = \"rdf:about\")                   \n",
    "        elif len(_tree) == 3:\n",
    "            elem3 = etree.SubElement(elem2, \"elem\", tag = _tag, label = node['name'], nodeid= node['nodeid'], isrequired = str(node['isrequired']), isvisible = str(node['isvisible']))\n",
    "            if node['datatype'] == 'resource-instance':\n",
    "                elem3.attrib['uriCheck']= 'True'\n",
    "                elem3.attrib['attrs']= 'rdf:resource'\n",
    "            if node['datatype'] == 'semantic':\n",
    "                elem3.attrib['unmappable']= 'True'        \n",
    "        elif len(_tree) == 4:\n",
    "            elem4 = etree.SubElement(elem3, \"elem\", tag = _tag, label = node['name'], nodeid= node['nodeid'], isrequired = str(node['isrequired']), isvisible = str(node['isvisible']))\n",
    "            if node['datatype'] == 'semantic':\n",
    "                elem4.attrib['unmappable']= 'True'\n",
    "        elif len(_tree) == 5:\n",
    "            elem5 = etree.SubElement(elem4, \"elem\", tag = _tag, label = node['name'], nodeid= node['nodeid'], isrequired = str(node['isrequired']), isvisible = str(node['isvisible']))\n",
    "            if node['datatype'] == 'semantic':\n",
    "                elem5.attrib['unmappable']= 'True'\n",
    "        elif len(_tree) == 6:\n",
    "            elem6 = etree.SubElement(elem5, \"elem\", tag = _tag, label = node['name'], nodeid= node['nodeid'], isrequired = str(node['isrequired']), isvisible = str(node['isvisible']))\n",
    "            if node['datatype'] == 'semantic':\n",
    "                elem6.attrib['unmappable']= 'True'\n",
    "        elif len(_tree) == 7:\n",
    "            elem7 = etree.SubElement(elem6, \"elem\", tag = _tag, label = node['name'], nodeid= node['nodeid'], isrequired = str(node['isrequired']), isvisible = str(node['isvisible']))\n",
    "            if node['datatype'] == 'semantic':\n",
    "                elem7.attrib['unmappable']= 'True'\n",
    "        elif len(_tree) == 8:\n",
    "            elem8 = etree.SubElement(elem7, \"elem\", tag = _tag, label = node['name'], nodeid= node['nodeid'], isrequired = str(node['isrequired']), isvisible = str(node['isvisible']))\n",
    "            if node['datatype'] == 'semantic':\n",
    "                elem8.attrib['unmappable']= 'True'\n",
    "        else:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "    return etree.tostring(root, encoding='utf-8', method='xml', pretty_print=True).decode() \n",
    "\n",
    "# TMP for checking things\n",
    "#import ast\n",
    "#generic = lambda x: ast.literal_eval(x)\n",
    "#conv = {'ns_path': generic}\n",
    "#tmp_graph = pd.read_csv('exporter/out/10_graph_ns_path.csv', converters=conv)    \n",
    "\n",
    "rec_def = make_rec_defs(graph)\n",
    "#rec_def = make_rec_defs(graph)\n",
    "print(rec_def)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d177ae-db73-4f2c-80d3-7346e0f3b9a3",
   "metadata": {},
   "source": [
    "## Make documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4074ebb3-028a-4df9-8659-90205eac79c6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_doc_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m     item_doc \u001b[38;5;241m=\u001b[39m etree\u001b[38;5;241m.\u001b[39mtostring(root, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxml\u001b[39m\u001b[38;5;124m'\u001b[39m, pretty_print\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdecode()        \n\u001b[1;32m     25\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m item_doc    \n\u001b[0;32m---> 27\u001b[0m docss \u001b[38;5;241m=\u001b[39m \u001b[43mmake_docs_xml\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(docss)\n",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m, in \u001b[0;36mmake_docs_xml\u001b[0;34m(_graph)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmake_docs_xml\u001b[39m(_graph):\n\u001b[0;32m----> 3\u001b[0m     doc_list \u001b[38;5;241m=\u001b[39m \u001b[43mmake_doc_paths\u001b[49m(_graph)    \n\u001b[1;32m      4\u001b[0m     item_list \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      5\u001b[0m     root \u001b[38;5;241m=\u001b[39m etree\u001b[38;5;241m.\u001b[39mElement(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdocs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_doc_paths' is not defined"
     ]
    }
   ],
   "source": [
    "def make_docs_xml(_graph):\n",
    "        \n",
    "    doc_list = make_doc_paths(_graph)    \n",
    "    item_list = []\n",
    "    root = etree.Element(\"docs\")\n",
    "    for item in doc_list:            \n",
    "        doc_path = '/'.join(item['path'])\n",
    "        doc = etree.SubElement(root, \"doc\", nodeid = item['nodeid'], path = doc_path)  \n",
    "        para = etree.SubElement(doc, \"para\", name= \"Label\") \n",
    "        para.text = item['name']\n",
    "        para = etree.SubElement(doc, \"para\", name= \"Description\") \n",
    "        para.text = str(item['description'])\n",
    "        para = etree.SubElement(doc, \"para\", name= \"Instructions\") \n",
    "        para.text = str(item['instructions'])\n",
    "        para = etree.SubElement(doc, \"para\", name= \"Helptitle\") \n",
    "        para.text = str(item['helptitle'])\n",
    "        para = etree.SubElement(doc, \"para\", name= \"Helptext\") \n",
    "        para.text = str(item['helptitle'])\n",
    "        para = etree.SubElement(doc, \"para\", name= \"Datatype\") \n",
    "        para.text = str(item['datatype'])\n",
    "        para = etree.SubElement(doc, \"para\", name= \"Required\") \n",
    "        para.text = str(item['isrequired'])\n",
    "        \n",
    "    item_doc = etree.tostring(root, encoding='utf-8', method='xml', pretty_print=True).decode()        \n",
    "    return item_doc    \n",
    "\n",
    "docss = make_docs_xml(graph)\n",
    "print(docss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c55680-98b3-423b-9a00-c79544c3d047",
   "metadata": {},
   "source": [
    "## Make Opts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb0a06f4-4036-4eee-9169-cd48ab3a7537",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 33\u001b[0m\n\u001b[1;32m     30\u001b[0m     concept_file \u001b[38;5;241m=\u001b[39m get_mapping(_uuid)\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [concept_file[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputfile\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mgetvalue()]\n\u001b[0;32m---> 33\u001b[0m _concepts \u001b[38;5;241m=\u001b[39m \u001b[43mget_concepts_as_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_uuid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m#_graph = pd.read_csv('mapper/out/10_graph_ns_path.csv', dtype={'sip_path':str })\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(_concepts[\u001b[38;5;241m0\u001b[39m])\n",
      "Cell \u001b[0;32mIn[8], line 30\u001b[0m, in \u001b[0;36mget_concepts_as_json\u001b[0;34m(_uuid)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concepts_as_json\u001b[39m(_uuid):\n\u001b[0;32m---> 30\u001b[0m     concept_file \u001b[38;5;241m=\u001b[39m \u001b[43mget_mapping\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_uuid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [concept_file[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutputfile\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mgetvalue()]\n",
      "File \u001b[0;32m~/PycharmProjects/Oslo/venv/lib/python3.9/site-packages/arches/app/utils/data_management/resource_graphs/exporter.py:189\u001b[0m, in \u001b[0;36mcreate_mapping_configuration_file\u001b[0;34m(graphid, include_concepts, data_dir)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    187\u001b[0m     node_query \u001b[38;5;241m=\u001b[39m Node\u001b[38;5;241m.\u001b[39mobjects\u001b[38;5;241m.\u001b[39mfilter(graph_id\u001b[38;5;241m=\u001b[39mgraphid)\u001b[38;5;241m.\u001b[39mexclude(datatype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msemantic\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39morder_by(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 189\u001b[0m export_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresource_model_id\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[43mnode_query\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mgraph_id)\n\u001b[1;32m    190\u001b[0m export_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresource_model_name\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m JSONSerializer()\u001b[38;5;241m.\u001b[39mserializeToPython(\n\u001b[1;32m    191\u001b[0m     Graph\u001b[38;5;241m.\u001b[39mobjects\u001b[38;5;241m.\u001b[39mfilter(graphid\u001b[38;5;241m=\u001b[39mexport_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresource_model_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    192\u001b[0m )[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    193\u001b[0m export_json[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnodes\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/PycharmProjects/Oslo/venv/lib/python3.9/site-packages/django/db/models/query.py:318\u001b[0m, in \u001b[0;36mQuerySet.__getitem__\u001b[0;34m(self, k)\u001b[0m\n\u001b[1;32m    316\u001b[0m qs\u001b[38;5;241m.\u001b[39mquery\u001b[38;5;241m.\u001b[39mset_limits(k, k \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    317\u001b[0m qs\u001b[38;5;241m.\u001b[39m_fetch_all()\n\u001b[0;32m--> 318\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mqs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_result_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "def make_opts(graph, concepts):\n",
    "    \n",
    "    ns_list = make_doc_paths(graph)\n",
    "    root = etree.Element(\"opts\")    \n",
    "    for item in ns_list:\n",
    "        opt_path = item['path']\n",
    "        \n",
    "        \n",
    "        #\n",
    "        # NOT OK, just a name matching at the moment. It needs to be matched against UUIDs since dictionary and displayName can be different.\n",
    "        # Not avialble in the built in concept export so pull directly from the database\n",
    "        # Use just one language! \n",
    "        #   <opt value=\"Anmerkung\"/>\n",
    "        #   <opt value=\"annotaties\"/>\n",
    "        #   <opt value=\"annotations\"/>\n",
    "        \n",
    "        for k,v in json.loads(concepts).items():\n",
    "            if item['name'] == k:\n",
    "            \n",
    "                opt_path = '/'.join(item['path'])\n",
    "                opt_list = etree.SubElement(root, \"opt-list\", dictionary=item['name'], path=opt_path, displayName=item['name'])  \n",
    "                for _opt in v.values():\n",
    "                    opt = etree.SubElement(opt_list, \"opt\", value=_opt)\n",
    "\n",
    "    _opts = etree.tostring(root, encoding='utf-8', method='xml', pretty_print=True).decode()        \n",
    "    print(_opts)\n",
    "\n",
    "\n",
    "def get_concepts_as_json(_uuid):\n",
    "    concept_file = get_mapping(_uuid)\n",
    "    return [concept_file[0]['outputfile'].getvalue()]\n",
    "\n",
    "_concepts = get_concepts_as_json(dataset_uuid)\n",
    "#_graph = pd.read_csv('mapper/out/10_graph_ns_path.csv', dtype={'sip_path':str })\n",
    "\n",
    "print(_concepts[0])\n",
    "\n",
    "#all_opts = make_opts(graph, _concepts[0])\n",
    "#print(all_opts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa32fc1-f498-4800-a916-6d485796cbef",
   "metadata": {},
   "source": [
    "## Make mermaid graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84d4df07-e104-4763-887d-dea1477d8ceb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_doc_paths' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 23\u001b[0m\n\u001b[1;32m     19\u001b[0m                 m_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m--> \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m (v\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m), k\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n\u001b[1;32m     21\u001b[0m     render_graph(\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(m_list))                   \n\u001b[0;32m---> 23\u001b[0m mermaid_graph \u001b[38;5;241m=\u001b[39m \u001b[43mmake_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#mermaid_graph = render_graph(n_graph)    \u001b[39;00m\n",
      "Cell \u001b[0;32mIn[7], line 12\u001b[0m, in \u001b[0;36mmake_graph\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m      9\u001b[0m     display(Image(url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://mermaid.ink/img/\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m base64_string))\n\u001b[1;32m     11\u001b[0m m_list \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 12\u001b[0m g_list \u001b[38;5;241m=\u001b[39m \u001b[43mmake_doc_paths\u001b[49m(graph)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m#print(json.dumps(g_list, indent=2))\u001b[39;00m\n\u001b[1;32m     14\u001b[0m m_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgraph LR;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'make_doc_paths' is not defined"
     ]
    }
   ],
   "source": [
    "#A[Square Rect] -- Link text --> B((Circle))\n",
    "\n",
    "def make_graph(graph):\n",
    "    \n",
    "    def render_graph(m_str):\n",
    "        graphbytes = m_str.encode(\"ascii\")\n",
    "        base64_bytes = base64.b64encode(graphbytes)\n",
    "        base64_string = base64_bytes.decode(\"ascii\")\n",
    "        display(Image(url=\"https://mermaid.ink/img/\" + base64_string))\n",
    "    \n",
    "    m_list = []\n",
    "    g_list = make_doc_paths(graph)\n",
    "    #print(json.dumps(g_list, indent=2))\n",
    "    m_list.append('graph LR;')\n",
    "    \n",
    "    for item in g_list:        \n",
    "        for k, v in item['relation'].items():\n",
    "            if v != 'root':\n",
    "                m_list.append('%s--> %s;' % (v.replace(' ', '_'), k.replace(' ', '_')))\n",
    "    \n",
    "    render_graph('\\n'.join(m_list))                   \n",
    "    \n",
    "mermaid_graph = make_graph(graph)    \n",
    "#mermaid_graph = render_graph(n_graph)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c623f3ad-0193-4028-8768-7336374e86fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
